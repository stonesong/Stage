\section{Analyse des études antérieures et recommandations}
\label{sec:analyse}

Dans cette partie, nous procédons à l’analyse d’études antérieures sur la prédiction de bugs qui ont utilisé les métriques de procédés pour la prédiction de bugs. Nous évaluons si les valeurs des métriques de procédés pourraient être biaisées en regardant la façon dont ils ont recueilli leurs données.

Enfin, nous donnons quelques lignes de conduite à suivre pour aider les chercheurs et développeurs à éviter l’impact que le renommage d’entités pourrait avoir sur les métriques de procédés.  

\subsection{Analyse des études antérieures}

Premièrement, comme nous l'avons montré dans la \secref{resultats}, il est important de remarquer que les périodes contenant un taux de fichiers renommés élevés sont rares. Ainsi, la majeure partie des études antérieures ne devraient pas être affectées par ce phénomène. 

De plus, même dans le cas d'analyses sur des périodes contenant un taux élevé de fichiers renommés, les résultats de ces analyses pourraient également être améliorés, car les métriques de procédés auraient probablement été sous-estimées. Toutefois, plusieurs études antérieures peuvent être affectées par le renommage, comme nous le signalerons dans la suite de cette section. Quantifier de tels effets sur les études antérieures est hors de portée de notre sujet, mais nous fournissons tout de même certaines lignes de conduite à respecter pour les études futures.\\

Dans notre examen des études antérieures, nous n'analysons que $26$ des articles référencés dans ~\cite{radjenovic_software_2013}. Les articles qui utilisent les trois métriques de procédés, CC, NoD ou NoC. Cependant, certaines des autres études référencées dans cet article utilisent d'autres métriques de procédés et pourraient donc aussi être affectées par le renommage.\\

$15$ de ces études analysent des projets industriels, ~\cite{arisholm_systematic_2010,graves_predicting_2000,khoshgoftaar_using_2000,layman_iterative_2008,munson_code_1998,nagappan_use_2005,nagappan_influence_2008,nagappan_using_2007,nagappan_using_2006,nagappan_change_2010,nikora_building_2006,ostrand_programmer-based_2010,weyuker_too_2008,weyuker_using_2007,yuan_application_2000}. Aucune de ces études ne parle de renommage. Mais le manque d'informations récoltées sur les VCS utilisés et sur le projet en lui-même, ne nous permet pas de savoir si le renommage pouvait avoir un impact sur ces projets. Néanmoins, l'article de Kim et al ~\cite{kim_field_2012} explique que les développeurs dans son étude effectuent des opérations de refactoring, dont du renommage, sans utiliser les outils du VCS appropriés. Ainsi, ces études pourraient être impactées par le renommage en fonction des outils utilisés et des habitudes de développement.\\

$11$ études analysent des logiciels open-source \cite{dambros_relationship_2009,bacchelli_are_2010,caglayan_merits_2009,dambros_evaluating_2012,dambros_evaluating_2012,dambros_extensive_2010,illes-seifert_exploring_2010,li_finding_2005,matsumoto_analysis_2010,moser_analysis_2008,moser_comparative_2008,schroter_if_2006}. Les VCS utilisés dans ces études sont CVS ou Subversion. CVS ne gère pas le renommage et Subversion uniquement de manière manuelle ce qui est dangereux comme expliqué dans l'article ~\cite{lavoie_inferring_2012,steidl_incremental_2014}. Seulement deux de ces études ~\cite{moser_analysis_2008,moser_comparative_2008} parlent de renommage, dans leur set de données ou dans les ''Threats to validity''. Pour réduire le risque d'erreur dans leurs expérimentations, ces deux études ont supprimé systématiquement tous les fichiers ajoutés ou supprimés durant les périodes analysées. C'est un bon moyen d'éviter de calculer des métriques de procédés biaisés, mais cela implique aussi de supprimer inutilement, du jeu de données, un nombre significatif de fichiers.\\

\subsection{Recommandations}
\label{sec:guidelines}

Les résultats de nos deux expérimentations nous permettent de déduire de simples lignes de conduite pour calculer les métriques de procédés. Voici donc nos recommandations: 
\begin{itemize}
\item Eviter de calculer ces métriques durant les périodes initiales. En effet, ces périodes contiennent habituellement une quantité de renommage significative. Comme nous l'avons vu, les deux périodes majeures et mineures peuvent contenir un beaucoup de renommage, bien que les releases majeures semblent plus sujettes au renommage. 
\item Utiliser systématiquement un algorithme de détection de renommage, afin d'éviter d'analyser les mauvaises périodes. Git propose un algorithme dédié qui semble avoir une bonne précision mais un rappel inconnu. Par conséquent, l'utilisation de projets gérés avec Git parait la méthode la plus simple pour diminuer les risques du renommage. Des algorithmes de détection plus avancés sont décrits dans la littérature ~\cite{antoniol_automatic_2004,lavoie_inferring_2012,steidl_incremental_2014}. Ils ont été validés par des études empiriques donc ils pourraient réaliser une analyse meilleure que celle de Git. 
\item Pour les métriques de procédés calculées à des niveaux de granularité plus fins que celui des fichiers, utiliser les algorithmes d``Origin Analysis'' tels que ~\cite{wu_aura:_2010}. Ces algorithmes sont efficaces au niveau de granularité des fonctions.
\item Le renommage d'entités peut être un risque important, penser à indiquer systématiquement comment il a été traité dans les études futures.\\       
\end{itemize}
