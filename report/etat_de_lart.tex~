\section{Etat de l'art}
\label{sec:etat_de_lart}

\subsection{Evolution logiciel et refactoring}
On peut régulièrement lire en introduction d'articles des propos sur l'importance du refactoring, ce qui inclue le renommage. Sur l'intérêt des techniques de compréhension de l’évolution des architectures et structures des logiciels. Les logiciels à succès sont généralement amenés à évoluer dans le temps, à se restructurer etc, après découverte de bugs, l’ajout de fonctionnalités, l’adaptation à l’environnement dans lequel ils évoluent. Le maintient d’un tel logiciel passe par la compréhension des choix d’architecture pris par le passé, par son histoire ~\cite{tu_integrated_2002,godfrey_tracking_2002,kim_field_2012}. Néanmoins on obtient pas de chiffres précis sur le nombre de renames. Uniquement dans l'étude de Kim et al un pourcentage de rename sur les operations de refactoring.\\

\begin{table}
\centering
\begin{tabular}{rccc}
\toprule
 & \multicolumn{3}{c}{Renaming handling}\\
\cmidrule{2-4}
& & \multicolumn{2}{c}{Automatic}\\
\cmidrule{3-4}
Tool & Manual & Standard & Optional\\
\midrule
CVS & & &\\
Subversion & $\times$ & &\\
Mercurial & $\times$ & & $\times$\\
Git & & & $\times$\\
\bottomrule
\end{tabular}
\caption{Handling of renaming of the main VCS tools.}
\label{tab:vcs}
\end{table}

\subsection{Les outils}

Intéressons nous aux outils disponibles pour la gestion de code source. Il existe un certains nombre de gestionnaires de versions tels que SVN, CVS, Mercurial ou Git qui pourraient être compatible avec notre étude étant donné que nous avons simplement besoin de versions, c'est à dire un état du projet à un moment donné de son histoire, à comparer entre elles. Nous avons néhanmoins étudié les VCS en détails et découvert que tous ne gèrent pas le renommage de fichiers de la même manière. La ~\tabref{vcs} résume notre étude. Alors que CVS ne gère pas du tout le renommage, SVN ou Mercural propose un méchanisme manuel de détection de renommage de ficheirs. Git quant à lui propose un algorithme de détection de renommage automatique et optionnel. Pour les VCS utilisent une détection manuelle, celà implique que c'est aux développeurs d'utilisé les commandes appropriés. Cependant certaines études montrent que les développeurs n'utilise pas ces commandes systématiquement. Le renommage peut être effectués jusqu'à $89\%$ du temps sans utilisés les commandes adaptés ~\cite{lavoie_inferring_2012,steidl_incremental_2014}. De plus l'étude de Kim et al montre que $51$\% des développeurs n'utilisent pas les commandes prévues par le VCS pour le refactoring (incluant le renommage). Ces trois études éffectués sur des projets open-source et industriels, montrent qu'il est dangereux de compter sur le fait que les développeurs utilisent les commandes adéquates pour le refactoring.\\

\subsection{``Origin Analysis''}
Nous expliquons ici rapidement l'algorithme utilisé par Git pour la détection de renommage de fichiers. Celui-ci est connu sous sous le nom de ``Origin Analysis'' et est expliqué par Godfrey et al dans les articles, ~\cite{tu_integrated_2002,godfrey_tracking_2002,godfrey_using_2005}\\
Tout d'abord il faut considérer deux versions succéssives d'un projet. Deux ensembles d'entités (fichiers, fonctions..) qui composent leur versions respectives. Certaines entités ayant étés modifiés de la version à la suivante, certaines supprimés et d'autres ajoutés.
La première analyse est une analyse de Bertillonage qui consiste à choisir un nombre de métriques, puis comparer les entités avec ces métriques. On compare alors les entités supprimés avec les entités ajoutés d'une version à l'autre. Grace à la distance Euclidienne calculée à partir des métriques combiné avec une comparaison des nom des entités, nous obtenons une liste des renommages potentiels.\\
Les analyses suivantes expliqués par Godfrey sont des ameliorations de la première analyse mais qui ne sont efficace qu'à un niveau de granularité plus bas, au niveau des fonctions. Par exemple l'analyse de dépendance qui tracke les appels de fonctions, en comparent les fonctions appelantes et appelés. Ces analyse sont basés sur des seuils d'acceptabilités définit par l'utilisateur. Plus Godrey améliorera ces analyses, en prenant en compte par la suite les splits er merges de fonctions (algorithme inéficace au niveau des fichiers) plus l'utilisateur sera solicité. \\

\subsection{Métriques de procédés et évolution logiciel}
Les métriques de procédés (change metrics) permettent de calculer à quel point une entité de code source à été modifiée au cours d'une période donnée dans l'histoire d'un logiciel. On les utilises usuellement dans la dernière période avant la dernière version, l'objectif étant de prédire les bugs qui apparaitront lors de la prochaine release. Elles ne considère donc que les entités étant toujours présentes à la fin de la période et qui ont étés actives dans la période.\\
Radjenovic et al \cite{radjenovic_software_2013} identifient trois métriques de procédés les plus utilisés pour la prédiction de bugs: Le nombre de développeurs ~\cite{weyuker_too_2008} (Number of Developers, NoD), Le nombre de modifications ~\cite{graves_predicting_2000} (Number of Changes, NoC) et le Code Churn ~\cite{munson_code_1998} (CC). Nous donnerons une définition et une méthode précise pour les calculer dans nos expérimentations.\\

\subsection{Métriques et Renommage Existant}
Nous nous somme donc intéressés aux études passées qui pouvaient traiter les trois métriques de procédés cités ci-dessus dans la prédiction de bugs, et vérifiés si ces études avaient considérés le renommage de fichiers. L'article ~\cite{radjenovic_software_2013} de Rajenovi et al référence $26$ études sur ce sujet.\\\\ 
$15$ de ces études analyses des projets industriels, ~\cite{arisholm_systematic_2010,graves_predicting_2000,khoshgoftaar_using_2000,layman_iterative_2008,munson_code_1998,nagappan_use_2005,nagappan_influence_2008,nagappan_using_2007,nagappan_using_2006,nagappan_change_2010,nikora_building_2006,ostrand_programmer-based_2010,weyuker_too_2008,weyuker_using_2007,yuan_application_2000}. Aucune de ces études ne parle de renommage, mais le manque d'informations récoltés sur les VCS utilisés et sur le projet en lui même ne nous permet pas de savoir si le renommage aurait pu avoir un impact sur ces projets. Néanmoins, l'article de Kim et al ~\cite{kim_field_2012} explique que les dévelopeurs dans son étude effectuent des opérations de refactoring, dont du renommage, sans utiliser les outils du VCS appropriés. Ainsi ces études pourraient être impactés par le renommage en fonction des outils utilisés et des habitudes de dévelopement.\\\\ 

$11$ études analyse des logiciels open-source \cite{dambros_relationship_2009,bacchelli_are_2010,caglayan_merits_2009,dambros_evaluating_2012,dambros_evaluating_2012,dambros_extensive_2010,illes-seifert_exploring_2010,li_finding_2005,matsumoto_analysis_2010,moser_analysis_2008,moser_comparative_2008,schroter_if_2006}. Les VCS utilisés dans ces études sont CVS ou Subversion. CVS ne gère pas le renommage et Subversion uniquement de manière manuelle ce qui est dangereux comme expliqué dans l'article ~\cite{lavoie_inferring_2012,steidl_incremental_2014}. Seulement deux de ces études ~\cite{moser_analysis_2008,moser_comparative_2008} parlent de renommage dans leurt set de données ou dans les ``Threats to validiyy''. Pour réduire le risque d'erreur dans leurs expérimentations, ces dux études ont supprimés systématiquement out les fichiers ajoutés ou supprimés durant les périodes analysés. C'est un bon moyen de d'éviter de calculer des métriques de procédés biaisés, mais celà implique aussi de supprimer inutilement du jeux de données un nombre significatif de fichiers.\\


