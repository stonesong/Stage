\section{Métriques de procédés}
\label{sec:metriques}

Nous décrivons dans cette partie comment les métriques de procédés sont calculés. Puis, nous expliquons comment les fichiers renommés peuvent avoir un impact sur ces métriques. Enfin, nous décrivons comment les VCS, actuellement, traitent le renommage.

\subsection{Calcul des métriques de procédés}

Les métriques de procédés (change metrics) permettent de calculer à quel point une entité de code source a été modifiée au cours d'une période donnée dans l'histoire d'un logiciel. Pour la prédiction de bugs, elles sont utilisés usuellement dans la dernière période, c'est à dire entre l'avant dernière et la dernière version du projet. L'objectif est de prédire les bugs qui apparaîtront lors de la prochaine version, en particulié si cette version est une \texttt{release}, c'est à dire une sortie de logiciel dite stable. Elles ne considèrent donc que les entités étant toujours présentes à la fin de la période et qui ont étés actives dans la période. Elles excluent donc aussi les entités supprimés au cours de la période.\\

Un gestionnaire de versions (VCS) offre plusieurs moyens de calculer les métriques de procédés car il stocke les informations sur les entités modifiées à chaque nouvelle version, l'auteur de ces modifications, la date, etc. De plus, il permet la récupération du contenu de chaque entité et de l'ensemble d'un projet à une version donnée qu'on appelle un \texttt{``snapshot''}. Pour calculer ces métriques, il est donc possible d'analyser chaque entité modifiée lors d'une période puis de garder uniquement les entités toujours présentes à la dernière version de notre période.\\

Plus précisement, voici comment un VCS peut être utilisé pour calculer les trois métriques de procédés les plus utilisés: le nombre de développeurs (Number of Developers, NoD), le nombre de modifications  (Number of Changes, NoC) et le Code Churn (CC). 
\begin{enumerate}
\item Nous récupérons d'abord la dernière version du projet pour obtenir les entités existantes à la fin de la période considérée. On note $A$ cet ensemble d'entités.
\item Toujours grâce aux commandes git, nous récupérons toutes les modifications effectuées durant la période. On note $C$ l'ensemble des modifications dans l'ordre chronologique.
\item Troisièmement, nous parcourons cet ensemble de modifications en commençant par la plus ancienne ($c_0 \in C$) jusqu'à la plus récente ($c_n \in C$) dans le but de calculer les métriques de procédés pour chaque entité.
\end{enumerate}

 On note $\mu_{a}^{M}$ la valeur de la métrique $M$ pour l'entité $a$. Ensuite nous calculons les métriques comme suivant (on note $c_i$ la modification courante lors du parcours):
\begin{description}
	\item[NoD] (nombre de développeurs) Pour chaque entité $a$ pointé par $c_i$ qui appartient aussi à $A$ ($a \in A$), on ajoute à $\mu_{a}^{NoD}$ le nombre d'auteurs qui ont effectué les modifications $c_i$ et qui ont modifiés $a$ pour la première fois dans la période.
	\item[NoC] (nombre de modifications) Pour chaque entité $a$ pointé par $c_i$ qui appartient aussi à $A$ ($a \in A$), on ajoute $1$ à $\mu_{a}^{C}$ tels que $c_i$ indique qu'une nouvelle modification a été effectuée.
	\item[CC] (Code Churn) Pour chaque entité $a$ pointé par $c_i$ qui appartient aussi à $A$ ($a \in A$), on vérifie d'abord que la modification n'est pas une creation d'entité. Si c'est le cas celà veut dire que l'entité a été créée durant la période, donc on initialise son $\mu_{a}^{CC}$ à son nombre de lignes. Ensuite au prochain $c_j$ qui cible $a$ dans la période avec ($i < j$), on compare les deux versions et on ajoute à $\mu_{a}^{CC}$ le nombre de lignes ajoutées ou suprimées.
\end{description}


\subsection{Métriques de procédés et renommage}

Un VCS est donc particulièrement utile dans cet exercice. Cependant, il faut noter qu'un VCS identifie une entité par son chemin $+$ son nom. Le chemin représente l'ensemble des dossiers parents depuis la racine du projet. On en déduit qu'un renommage du fichier ou d'un dossier, aura un impact sur le calcul des métriques. Pour expliquer cet impact, il est présenté un exemple d'historique d'un logiciel figure 2. Ce projet ne contient qu'une entité, Test.php, qui est renommé en Hello.php dans la dernière version. Dans cet exemple nous calculons les trois métriques NoD, NoC et CC entre la version 1 et 3.\\

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\linewidth,keepaspectratio]{data/figures/example.pdf}
	\caption{Exemple d'un historique de projet. Le projet est composé d'un seul fichier \texttt{Test.php} qui est renommé en \texttt{Hello.php} dans la dernière version.}
	\label{fig:example}
\end{figure}

La dernière version de la période ne contient qu'une entité, \texttt{Hello.php}. En conséquence uniquement cette entité sera considérée par les techniques qui visent à prédire les bugs. Si on ne prend pas en compte le renommage, l'entité n'apparaît que dans la version 3. Ainsi, le calcul est trivial, étant donné qu'il n'y a qu'un seul développeur alors $\mu^{NoD}=1$. Il n'y a qu'une seule modification, la creation du fichier \texttt{Hello.php}, donc $\mu^{NoC}=1$. La création du fichier implique l'ajout de deux lignes de codes donc $\mu^{CC}=2$.\\

Par ailleurs, en prenant en compte le fait que ce fichier a été renommé, il y a trois versions à considérer en ce qui concerne l'entité. Le premier nom du fichier était Test.php. Les valeurs des métrique de procédés change donc completement. Ce fichier a eu un premier auteur lors de la version $1$ puis un deuxième à la version $2$. Le fichier est ensuite renommé en Hello.php par un troisième auteur donc $\mu^{NoD}=3$. Le fichier a subie trois modifications, la creation du fichier version $1$, une modification du contenu version $2$ et un renommage version $3$ donc $\mu^{NoC}=3$. Enfin, pour le Code Churn, la création du fichier implique l'ajout d'$1$ ligne de code, la modification de cette ligne version $2$ implique la suppression d'$1$ ligne plus l'ajout d'$1$ ligne de code et la version 3, l'ajout d'$1$ ligne de commentaire. Nous avons donc maintenant $\mu^{CC}=4$. \\

Notre exemple montre que le renommage d'entité de code source peut bisaiser le calcul des métriques de procédés. Plus généralement, les valeurs des métriques NoD et NoC peuvent seulement être plus grande lorsque le renommage est pris en compte étant donné que plus une entité est ancienne plus elle a de chances d'avoir un nombre de développeurs et de modifications élevés. La valeur du Code Churn quant à elle, peut augmenter ou diminuer si le renomage est pris en compte. En effet, comme nous l'avons vue dans l'exemple, un renommage d'entité est considéré comme la suppression d'une entité et l'ajout d'une nouvelle entité si le renommage n'est pas pris en compte. Le renommage d'une entité dans une période induit donc que l'entité renommée a été crée durant la période. Cela entraine l'ajout du nombre de lignes de la nouvelle entité à la métrique CC à la version où elle a été renommée. Ainsi, si l'entité est considérable, son CC sera bien plus important qu'il ne devrait. Un autre effet intérressant à remarquer est que plus une entité est renommée proche de la fin de la période, pire sera l'effet. En particulier, si elle est renommée juste avant la dernière version, alors tous les changements préalable qu'elle a subie seront perdus.\\

\subsection{Renommage et VCS}

Nous avons effectué une analyse approfondie des principaux VCS (CVS, Subversion, Git and Mercurial) dans le but de décrire les mécanismes qu'ils proposent pour traiter le renommage. Tous ces VCS sont à une granularité d'entité au niveau fichier. Comme dis précédemment, les entités, ici des fichiers donc, sont identifiés par leur chemin absolue, c'est à dire le chemin depuis la racine du projet $+$ leur nom. Pour tout ces VCS, une modification dans le chemin d'un fichier, qui peut être due à un changement d'emplacement dans les dossiers ou à un changement de son nom, est considéré comme une suppression de fichier et création de fichier. Certains VCS proposent en complément un mécanisme pour traiter les renommages. Ce mécanisme peut être manuel ou automatique. Un mécanisme de traitement de renommage est dis manuel lorsque le développeurs doit utiliser une commande particulière pour indiquer que la modification effectuée sur le fichier est un renommage. Un mécanisme est automatique lorsque le VCS propose un algorithm qui peut automatiquement détecter le renommage. De plus, ce mécanisme automatique peut être appliqué par défaut par le VCS ou de manière optionnelle lorsque le développeur doit explicitement ajouter une option de commande dans sa recherche dans l'historique.\\
 
La ~\tabref{vcs} résume notre étude. Alors que CVS ne gère pas du tout le renommage, SVN ou Mercural propose un mécanisme manuel de détection de renommage de fichiers. Git quant à lui propose un algorithme de détection de renommage automatique mais optionnel. Aucun de ces VCS ne propose un mécanisme automatique par défaut. Le traitement du renommage de ces VCS ne parvient cepandant pas à limiter l'impact sur le calcul des métriques de procédés.\\ 

\begin{table}[h]
\centering
\begin{tabular}{rccc}
\toprule
 & \multicolumn{3}{c}{Renaming handling}\\
\cmidrule{2-4}
& & \multicolumn{2}{c}{Automatic}\\
\cmidrule{3-4}
Tool & Manual & Standard & Optional\\
\midrule
CVS & & &\\
Subversion & $\times$ & &\\
Mercurial & $\times$ & & $\times$\\
Git & & & $\times$\\
\bottomrule
\end{tabular}
\caption{Traitement du renommage des principaux VCS.}
\label{tab:vcs}
\end{table}

Pour les VCS qui utilisent une détection manuelle, cela implique que c'est aux développeurs d'utiliser les commandes appropriées. Cependant certaines études montrent que les développeurs n'utilisent pas ces commandes systématiquement. Le renommage peut être effectué jusqu'à $89\%$ du temps sans utiliser les commandes adaptées ~\cite{lavoie_inferring_2012,steidl_incremental_2014}. De plus l'étude de Kim et al ~\cite{kim_field_2012} montre que $51$\% des développeurs n'utilisent pas les commandes prévues par le VCS pour le refactoring (incluant le renommage). Ces trois études effectuées sur des projets open-source et industriels, montrent qu'il est dangereux de compter sur le fait que les développeurs utilisent les commandes adéquates pour le refactoring.\\

Par ailleurs, le traitement automatique optionnel du renommage nécessite une certaine connaissance des paramètres interne du VCS, afin de choisir la bonne option pour gérer le renommage. Cependant, nous n'avons jamais trouvé d'explications à propos de la configuration d'un VCS et de ses options dans aucune étude ayant pour but la prédiction de bug avec l'utilisation de métriques de procédés. Ce n'est pas réellement surprenant comme nous décrivons dans la Section 5, dans notre analyse des études passés, qu'aucune d'elle n'a jamais utilisé Git comme gestionnaire de version, le seul à proposer un traitement automatique optionnel du renommage.\\

Le mécanisme proposé par Git utilise un algorithme nommé ``Origin Analysis''.

\subsection{``Origin Analysis''}

Nous expliquons ici succinctement l'algorithme utilisé par Git pour la détection de renommage de fichiers. Celui-ci est connu sous le nom de ``Origin Analysis'' et est expliqué par Godfrey et al dans les articles ~\cite{tu_integrated_2002,godfrey_tracking_2002,godfrey_using_2005}.

Tout d'abord, il faut considérer deux versions successives d'un projet. Deux ensembles d'entités (fichiers, fonctions..) qui composent leurs versions respectives. Certaines entités ayant été modifiées, certaines supprimées et d'autres ajoutées.
La première analyse est une analyse de Bertillonage qui consiste à choisir un nombre de métriques, puis comparer les entités avec ces métriques. On compare alors les entités supprimées avec les entités ajoutées d'une version à l'autre. Grace à la distance Euclidienne calculée à partir des métriques combinés avec une comparaison des noms des entités, nous obtenons une liste des renommages potentiels.

Les analyses suivantes expliquées par Godfrey sont des améliorations de la première analyse, mais qui ne sont efficaces qu'à un niveau de granularité plus bas, c'est à dire une finesse d'analyse plus précise, en l'occurence au niveau des fonctions. Par exemple, l'analyse de dépendance qui traque les appels de fonctions, en comparant les fonctions appelantes et appelées. Ces analyses sont basées sur des seuils d'acceptabilité défini par l'utilisateur. Plus Godrey améliorera ces analyses, en prenant en compte par la suite les splits er merges de fonctions (algorithme inefficace au niveau des fichiers) plus l'utilisateur sera sollicité. (TODO: détailler ?)\\
