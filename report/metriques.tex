\section{Métriques de procédés}
\label{sec:metriques}

Nous décrivons dans cette partie comment les métriques de procédés sont calculées. Puis, nous expliquons comment les fichiers renommés peuvent avoir un impact sur ces métriques. Enfin, nous décrivons comment les VCS, actuellement, traitent le renommage.

\subsection{Calcul des métriques de procédés}

Les métriques de procédés (change metrics) permettent de calculer à quel point une entité de code source a été modifiée au cours d'une période donnée dans l'histoire d'un logiciel. Pour la prédiction de bugs, elles sont utilisées usuellement dans la dernière période, c'est à dire entre l'avant dernière et la dernière version du projet. L'objectif est de prédire les bugs qui apparaîtront lors de la prochaine version, en particulier si cette version est une \texttt{release}, c'est à dire une sortie de logiciel dite stable. Elles ne considèrent donc que les entités étant toujours présentes à la fin de la période et qui ont étés actives dans la période. Elles excluent donc aussi les entités supprimées au cours de la période.\\

Un gestionnaire de versions (VCS) offre plusieurs moyens de calculer les métriques de procédés car il stocke les informations sur les entités modifiées à chaque nouvelle version, l'auteur de ces modifications, la date, etc. De plus, il permet la récupération du contenu de chaque entité et de l'ensemble d'un projet à une version donnée qu'on appelle un \texttt{``snapshot''}. Pour calculer ces métriques, il est donc possible d'analyser chaque entité modifiée lors d'une période puis de garder uniquement les entités toujours présentes à la dernière version de notre période.\\

Plus précisément, voici comment un VCS peut être utilisé pour calculer les trois métriques de procédés les plus utilisés: le nombre de développeurs (Number of Developers, NoD), le nombre de modifications  (Number of Changes, NoC) et le Code Churn (CC). 
\begin{enumerate}
\item Nous récupérons d'abord la dernière version du projet pour obtenir les entités existantes à la fin de la période considérée. On note $A$ cet ensemble d'entités.
\item Toujours grâce aux commandes Git, nous récupérons toutes les modifications effectuées durant la période. On note $C$ l'ensemble des modifications dans l'ordre chronologique.
\item Troisièmement, nous parcourons cet ensemble de modifications en commençant par la plus ancienne ($c_0 \in C$) jusqu'à la plus récente ($c_n \in C$) dans le but de calculer les métriques de procédés pour chaque entité.
\end{enumerate}

 On note $\mu_{a}^{M}$ la valeur de la métrique $M$ pour l'entité $a$. Ensuite nous calculons les métriques comme suivant (on note $c_i$ la modification courante lors du parcours):
\begin{description}
	\item[NoD] (nombre de développeurs) Pour chaque entité $a$ pointé par $c_i$ qui appartient aussi à $A$ ($a \in A$), on ajoute à $\mu_{a}^{NoD}$ le nombre d'auteurs qui ont effectué les modifications $c_i$ et qui ont modifiés $a$ pour la première fois dans la période.
	\item[NoC] (nombre de modifications) Pour chaque entité $a$ pointé par $c_i$ qui appartient aussi à $A$ ($a \in A$), on ajoute $1$ à $\mu_{a}^{C}$ tels que $c_i$ indique qu'une nouvelle modification a été effectuée.
	\item[CC] (Code Churn) Pour chaque entité $a$ pointé par $c_i$ qui appartient aussi à $A$ ($a \in A$), on vérifie d'abord que la modification n'est pas une création d'entité. Si c'est le cas celà signifie que l'entité a été créée durant la période, donc on initialise son $\mu_{a}^{CC}$ à son nombre de lignes. Ensuite au prochain $c_j$ qui cible $a$ dans la période avec ($i < j$), on compare les deux versions et on ajoute à $\mu_{a}^{CC}$ le nombre de lignes ajoutées ou supprimées.
\end{description}


\subsection{Métriques de procédés et renommage}

Un VCS est donc particulièrement utile dans cet exercice. Cependant, il faut noter qu'un VCS identifie une entité par son chemin $+$ son nom. Le chemin représente l'ensemble des dossiers parents depuis la racine du projet. On en déduit qu'un renommage du fichier ou d'un dossier, aura un impact sur le calcul des métriques. Pour expliquer cet impact, il est présenté un exemple d'historique d'un logiciel figure 2. Ce projet ne contient qu'une entité, Test.php, qui est renommé en Hello.php dans la dernière version. Dans cet exemple, nous calculons les trois métriques NoD, NoC et CC entre la version 1 et 3.\\

\begin{figure}[t]
	\centering
	\includegraphics[width=0.8\linewidth,keepaspectratio]{data/figures/example.pdf}
	\caption{Exemple d'un historique de projet. Le projet est composé d'un seul fichier \texttt{Test.php} qui est renommé en \texttt{Hello.php} dans la dernière version.}
	\label{fig:example}
\end{figure}

La dernière version de la période ne contient qu'une entité, \texttt{Hello.php}. En conséquence uniquement cette entité sera considérée par les techniques qui visent à prédire les bugs. Si on ne prend pas en compte le renommage, l'entité n'apparaît que dans la version 3. Ainsi, le calcul est trivial, étant donné qu'il n'y a qu'un seul développeur, alors $\mu^{NoD}=1$. Il n'y a qu'une seule modification, la creation du fichier \texttt{Hello.php}, donc $\mu^{NoC}=1$. La création du fichier implique l'ajout de deux lignes de codes donc $\mu^{CC}=2$.\\

Par ailleurs, en prenant en compte le fait que ce fichier a été renommé, il y a trois versions à considérer qui ciblent notre entité. Le premier nom du fichier était Test.php. Les valeurs des métriques de procédés changent donc completement. Ce fichier a eu un premier auteur lors de la version $1$ puis un deuxième à la version $2$. Le fichier est ensuite renommé en Hello.php par un troisième auteur donc $\mu^{NoD}=3$. Le fichier a subi trois modifications: la création du fichier version $1$, une modification du contenu version $2$ et un renommage version $3$ donc $\mu^{NoC}=3$. Enfin, pour le Code Churn, la création du fichier implique l'ajout d'$1$ ligne de code, la modification de cette ligne version $2$ implique la suppression d'$1$ ligne plus l'ajout d'$1$ ligne de code et la version 3, l'ajout d'$1$ ligne de commentaire. Nous avons donc maintenant $\mu^{CC}=4$. \\

Notre exemple montre que le renommage d'entité de code source peut biaiser le calcul des métriques de procédés. Plus généralement, lorsque le renommage est pris en compte, les valeurs des métriques NoD et NoC ne peuvent qu'avoir une valeur plus grandes. En effet, étant donné que plus une entité est ancienne plus elle a de chances d'avoir un nombre de développeurs et un nombre de modifications élevés. La valeur du Code Churn quant à elle, peut augmenter ou diminuer si le renommage est pris en compte. En effet, comme nous l'avons vue dans l'exemple précédent, un renommage d'entité est considéré comme la suppression d'une entité et l'ajout d'une nouvelle entité si le renommage n'est pas pris en compte. Le renommage d'une entité dans une période induit donc que l'entité renommée a été créée durant la période. Cela entraine l'ajout du nombre de lignes de la nouvelle entité à la métrique CC, à la version où elle a été renommée. Ainsi, si l'entité est considérable, son CC sera bien plus important qu'il ne devrait. Un autre effet intéressant à remarquer est que plus une entité est renommée proche de la fin de la période, pire sera l'effet. En particulier, si elle est renommée juste avant la dernière version, alors tous les changements préalables qu'elle a subis seront perdus.\\

\subsection{Renommage et VCS}

Nous avons effectué une analyse approfondie des principaux VCS (CVS, Subversion, Git and Mercurial) dans le but de décrire les mécanismes qu'ils proposent pour traiter le renommage. Tous ces VCS sont à une granularité d'entité au niveau fichier. Comme dis précédemment, les entités, ici des fichiers donc, sont identifiés par leur chemin absolu, c'est à dire le chemin depuis la racine du projet $+$ leur nom. Pour tous ces VCS, une modification dans le chemin d'un fichier, qui peut être due à un changement d'emplacement dans les dossiers ou à un changement de son nom, est considéré comme une suppression de fichier et création de fichier. Certains VCS proposent en complément un mécanisme pour traiter les renommages. Ce mécanisme peut être manuel ou automatique. Un mécanisme de traitement de renommage est dit manuel lorsque le développeur doit utiliser une commande particulière pour indiquer que la modification effectuée sur le fichier est un renommage. Un mécanisme est automatique lorsque le VCS propose un algorithme qui peut automatiquement détecter le renommage. De plus, ce mécanisme automatique peut être appliqué par défaut par le VCS ou de manière optionnelle lorsque le développeur doit explicitement ajouter une option de commande dans sa recherche dans l'historique.\\
 
La ~\tabref{vcs} résume notre étude. Alors que CVS ne gère pas du tout le renommage, SVN ou Mercural propose un mécanisme manuel de détection de renommage de fichiers. Git quant à lui propose un algorithme de détection de renommage automatique mais optionnel. Aucun de ces VCS ne propose un mécanisme automatique par défaut. Le traitement du renommage de ces VCS ne parvient cependant pas à limiter l'impact sur le calcul des métriques de procédés.\\ 

\begin{table}[h]
\centering
\begin{tabular}{rccc}
\toprule
 & \multicolumn{3}{c}{Renaming handling}\\
\cmidrule{2-4}
& & \multicolumn{2}{c}{Automatic}\\
\cmidrule{3-4}
Tool & Manual & Standard & Optional\\
\midrule
CVS & & &\\
Subversion & $\times$ & &\\
Mercurial & $\times$ & & $\times$\\
Git & & & $\times$\\
\bottomrule
\end{tabular}
\caption{Traitement du renommage des principaux VCS.}
\label{tab:vcs}
\end{table}

Pour les VCS qui utilisent une détection manuelle, cela implique que c'est aux développeurs d'utiliser les commandes appropriées. Cependant, certaines études montrent que les développeurs n'utilisent pas ces commandes systématiquement. Le renommage peut être effectué jusqu'à $89\%$ du temps sans utiliser les commandes adaptées ~\cite{lavoie_inferring_2012,steidl_incremental_2014}. De plus l'étude de Kim et al ~\cite{kim_field_2012} montre que $51$\% des développeurs n'utilisent pas les commandes prévues par le VCS pour le refactoring (incluant le renommage). Ces trois études effectuées sur des projets open-source et industriels, montrent qu'il est dangereux de compter sur le fait que les développeurs utilisent les commandes adéquates pour le refactoring.\\

Par ailleurs, le traitement automatique optionnel du renommage nécessite une certaine connaissance des paramètres interne du VCS, afin de choisir la bonne option pour gérer le renommage. Cependant, nous n'avons jamais trouvé d'explications à propos de la configuration d'un VCS et de ses options, dans aucune étude ayant pour but la prédiction de bug avec l'utilisation de métriques de procédés. Ce n'est pas réellement surprenan. Car comme nous le décrivons dans la Section 5, dans notre analyse des études passées, aucune d'elle n'a jamais utilisée Git comme gestionnaire de version, le seul à proposer un traitement automatique optionnel du renommage.\\

Le mécanisme proposé par Git utilise un algorithme nommé ``Origin Analysis''.

\subsection{``Origin Analysis''}

Nous expliquons ici succinctement l'algorithme utilisé par Git pour la détection de renommage de fichiers. Celui-ci est connu sous le nom de ``Origin Analysis'' et est expliqué par Godfrey et al dans les articles ~\cite{tu_integrated_2002,godfrey_tracking_2002,godfrey_using_2005}.\\

Tout d'abord, il faut considérer deux versions successives d'un projet. Une version est composé d'un ensemble d'entité (fichiers, fonctions..). D'une version à la suivante, certaines entités peuvent être modifiées, certaines supprimées et d'autres ajoutées.

La première analyse proposée par Godrey pour détecter les renommages d'une version à la suivante est une analyse de Bertillonage. Cette analyse consiste à comparer entre elles les entités composantes de chaque couple ``entité supprimée, entité créée'', d'une version à la suivante. Cette comparaison s'effectue grâce à un choix de plusieurs métriques (LOC, cyclomatic complexity etc..). La distance Euclidienne calculée, combinée avec une technique de comparaison des noms des entités, nous obtenons une liste des renommages potentiels ordonnée. Un seuil d'acceptabilité peut alors être définit pour juger si un couple compose un renommage d'entité.

Git met donc en application cette première ``Origin Analysis'' uniquement, avec un seuil d'acceptabilité établi par défaut mais qui peut être configuré à postériori.\\

Par la suite, les analyses de Godfrey sont des améliorations de la première analyse, mais qui ne sont efficaces qu'à un niveau de granularité plus bas, c'est à dire une finesse d'analyse plus précise, en l'occurence au niveau des fonctions. Par exemple, l'analyse des dépendances qui traque les appels de fonctions, en comparant les fonctions appelantes et appelées. Ces analyses sont basées sur plusieurs types de seuils d'acceptabilité devant à chaque fois être définis par l'utilisateur. Plus Godrey améliorera ces analyses, en prenant en compte par la suite les splits et merges de fonctions (algorithme inefficace au niveau des fichiers), plus l'utilisateur sera sollicité.\\


